{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d75a9995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from federated_learning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a673bd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "model = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "rng_seed = 0\n",
    "\n",
    "# Clients\n",
    "num_clients = 10\n",
    "private_dataset_size = 20\n",
    "\n",
    "# Dataset\n",
    "num_classes = 10\n",
    "input_shape = (1, 28, 28)  # MNIST grayscale images\n",
    "\n",
    "# Traing params\n",
    "learning_rate = 0.01\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "batch_size = 1\n",
    "rounds = 5\n",
    "epochs = 1\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "294292c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make reproducible\n",
    "random.seed(rng_seed)\n",
    "torch.manual_seed(rng_seed)\n",
    "np.random.seed(rng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c3326c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 10 client dataloaders\n",
      "Private dataset 0: [8, 1, 7, 2, 1, 7, 0, 3, 1, 7, 0, 0, 9, 7, 9, 8, 9, 3, 0, 1, 7, 5, 5, 2, 4, 9, 2, 5, 3, 5, 9, 7, 2, 2, 6, 0, 2, 6, 9, 8, 8, 9, 5, 3, 4, 0, 0, 5, 9, 1, 8, 8, 9, 1, 9, 4, 9, 8, 8, 0, 4, 5, 4, 7, 1, 1, 9, 1, 6, 8, 2, 9, 0, 3, 1, 9, 9, 2, 5, 4, 4, 9, 9, 2, 9, 7, 8, 5, 1, 8, 1, 0, 3, 6, 8, 0, 2, 8, 6, 6]. Missing: []\n",
      "Private dataset 1: [0, 4, 3, 9, 2, 3, 6, 0, 8, 2, 2, 3, 9, 4, 4, 7, 7, 0, 8, 2, 2, 9, 3, 1, 4, 2, 6, 8, 7, 1, 4, 5, 8, 8, 4, 3, 9, 2, 8, 1, 3, 9, 5, 0, 1, 7, 7, 2, 9, 8, 4, 5, 9, 9, 5, 6, 3, 3, 7, 4, 3, 0, 0, 6, 2, 7, 5, 5, 5, 5, 0, 1, 0, 9, 9, 2, 4, 6, 6, 6, 4, 3, 4, 7, 2, 3, 8, 9, 1, 4, 1, 9, 4, 5, 1, 8, 0, 0, 9, 5]. Missing: []\n",
      "Private dataset 2: [1, 0, 2, 6, 4, 9, 3, 4, 7, 6, 3, 0, 7, 2, 0, 6, 7, 3, 6, 5, 7, 7, 1, 2, 2, 8, 7, 4, 6, 1, 3, 6, 0, 5, 4, 9, 2, 6, 2, 0, 7, 0, 7, 8, 1, 6, 5, 0, 8, 6, 9, 9, 0, 9, 8, 6, 5, 8, 2, 5, 0, 3, 9, 8, 9, 3, 1, 4, 6, 8, 4, 4, 6, 7, 5, 9, 3, 7, 7, 4, 8, 4, 4, 8, 7, 9, 7, 3, 8, 6, 7, 7, 2, 1, 6, 4, 5, 0, 4, 0]. Missing: []\n",
      "Private dataset 3: [4, 1, 2, 9, 5, 3, 1, 6, 4, 3, 4, 7, 6, 0, 7, 7, 8, 7, 6, 3, 5, 8, 4, 8, 4, 2, 8, 5, 6, 5, 9, 9, 2, 5, 5, 7, 7, 7, 1, 6, 0, 0, 8, 1, 4, 5, 7, 6, 5, 7, 9, 8, 0, 0, 9, 7, 7, 2, 2, 8, 4, 4, 1, 4, 8, 6, 0, 5, 3, 8, 8, 0, 5, 1, 8, 2, 7, 4, 8, 9, 7, 1, 7, 1, 7, 3, 2, 0, 7, 1, 9, 3, 0, 1, 1, 5, 0, 4, 7, 3]. Missing: []\n",
      "Private dataset 4: [1, 7, 6, 0, 8, 0, 8, 8, 7, 7, 9, 0, 7, 2, 5, 7, 0, 9, 2, 2, 4, 9, 8, 6, 7, 4, 8, 8, 1, 6, 0, 4, 7, 2, 0, 7, 6, 2, 0, 4, 5, 5, 1, 8, 1, 1, 5, 0, 8, 4, 2, 4, 2, 6, 2, 5, 2, 5, 8, 7, 2, 4, 8, 6, 1, 4, 5, 6, 4, 1, 9, 1, 9, 8, 0, 1, 1, 7, 9, 2, 9, 4, 8, 7, 3, 3, 0, 2, 7, 6, 4, 7, 0, 7, 2, 8, 7, 5, 9, 3]. Missing: []\n",
      "Private dataset 5: [8, 7, 6, 1, 9, 7, 9, 9, 6, 7, 8, 8, 5, 3, 6, 6, 8, 0, 6, 8, 8, 0, 3, 2, 0, 8, 2, 6, 1, 1, 5, 1, 2, 2, 5, 3, 4, 7, 2, 7, 6, 8, 5, 6, 6, 1, 8, 6, 7, 7, 6, 1, 1, 9, 2, 0, 9, 7, 9, 8, 9, 4, 4, 3, 5, 8, 4, 1, 0, 6, 0, 8, 6, 2, 7, 5, 5, 8, 4, 9, 8, 8, 0, 0, 9, 2, 1, 5, 1, 9, 7, 6, 9, 7, 9, 1, 6, 0, 9, 5]. Missing: []\n",
      "Private dataset 6: [8, 6, 8, 7, 9, 0, 0, 1, 7, 1, 6, 2, 1, 7, 0, 6, 4, 8, 1, 3, 1, 0, 3, 6, 3, 0, 2, 0, 5, 4, 9, 9, 7, 3, 9, 3, 4, 1, 1, 6, 2, 9, 2, 3, 1, 0, 2, 6, 8, 6, 9, 0, 9, 7, 1, 9, 2, 7, 3, 6, 8, 7, 7, 6, 0, 1, 3, 5, 0, 3, 8, 8, 2, 8, 8, 4, 1, 3, 8, 1, 9, 7, 4, 8, 7, 6, 6, 2, 0, 8, 1, 0, 1, 2, 4, 4, 3, 7, 5, 8]. Missing: []\n",
      "Private dataset 7: [2, 8, 7, 4, 4, 6, 8, 0, 4, 4, 6, 5, 3, 8, 0, 4, 4, 2, 7, 2, 8, 1, 2, 5, 4, 8, 7, 0, 3, 3, 4, 5, 2, 3, 6, 3, 5, 9, 1, 2, 3, 3, 8, 6, 1, 4, 3, 6, 1, 3, 9, 5, 5, 1, 7, 5, 0, 4, 1, 0, 3, 2, 7, 2, 8, 7, 0, 9, 5, 5, 7, 2, 2, 2, 7, 1, 3, 3, 2, 0, 9, 8, 1, 8, 7, 8, 6, 5, 2, 6, 4, 8, 9, 7, 0, 8, 6, 7, 4, 9]. Missing: []\n",
      "Private dataset 8: [8, 9, 4, 8, 1, 0, 1, 7, 1, 1, 8, 1, 7, 7, 5, 7, 5, 0, 5, 1, 6, 0, 4, 9, 6, 4, 1, 1, 6, 5, 7, 1, 7, 6, 6, 8, 5, 0, 8, 7, 7, 2, 3, 1, 2, 8, 9, 2, 3, 8, 5, 5, 4, 2, 3, 9, 8, 9, 3, 5, 2, 0, 8, 8, 1, 4, 3, 2, 1, 3, 6, 7, 3, 9, 8, 6, 2, 6, 5, 1, 7, 0, 8, 4, 4, 6, 9, 1, 7, 9, 8, 0, 6, 3, 8, 3, 0, 9, 7, 6]. Missing: []\n",
      "Private dataset 9: [0, 1, 9, 6, 0, 5, 6, 0, 1, 9, 1, 2, 8, 8, 3, 3, 4, 6, 8, 8, 3, 3, 9, 0, 1, 5, 6, 1, 4, 5, 0, 1, 3, 1, 1, 9, 5, 4, 9, 4, 2, 7, 3, 5, 9, 0, 8, 7, 1, 0, 8, 0, 6, 0, 3, 5, 9, 1, 3, 0, 8, 8, 6, 5, 2, 6, 3, 4, 3, 4, 5, 8, 2, 1, 5, 4, 6, 7, 4, 5, 7, 7, 9, 1, 5, 7, 5, 6, 1, 5, 0, 1, 7, 0, 5, 1, 1, 0, 4, 8]. Missing: []\n"
     ]
    }
   ],
   "source": [
    "# Download and transform MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # normalization params for MNIST\n",
    "])\n",
    "\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "clients_dataloaders = []\n",
    "for i in range(num_clients):\n",
    "    client_indices = random.sample(range(len(mnist_train)), private_dataset_size)\n",
    "    client_subset = Subset(mnist_train, client_indices)\n",
    "    dataloader = DataLoader(client_subset, batch_size=batch_size, shuffle=True)\n",
    "    clients_dataloaders.append(dataloader)\n",
    "\n",
    "print(f\"Prepared {num_clients} client dataloaders\")\n",
    "\n",
    "# inspect private datasets\n",
    "for idx in range(len(clients_dataloaders)):\n",
    "    data = []\n",
    "    \n",
    "    for dp, y in clients_dataloaders[idx]:\n",
    "        data.append(int(y[0]))\n",
    "    print('Private dataset ', idx, ': ', data, '. Missing: ', [x for x in range(10) if x not in data], sep='')\n",
    "\n",
    "test_loader = DataLoader(dataset=mnist_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "142a2e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Round 2\n",
      "Round 3\n",
      "Round 4\n",
      "Round 5\n",
      "Federated learning simulation complete!\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "global_model, _ = federated_learning(\n",
    "    clients_dataloaders=clients_dataloaders,\n",
    "    input_shape=input_shape,\n",
    "    num_classes=num_classes,\n",
    "    lr=learning_rate,\n",
    "    criterion=loss_fn,\n",
    "    model=model,\n",
    "    rounds=rounds,\n",
    "    epochs=epochs,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"Federated learning simulation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0b5f8a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 19.00%\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "global_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = global_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "594116f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model to file\n",
    "torch.save(global_model.state_dict(), 'trained_model_MNIST.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
