{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e01fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from federated_learning import *\n",
    "from gradient_suppression import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00a1478f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "model = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "rng_seed = 0\n",
    "\n",
    "# Clients\n",
    "num_clients = 10\n",
    "private_dataset_size = 3\n",
    "\n",
    "# Dataset\n",
    "num_classes = 10\n",
    "input_shape = (1, 28, 28)  # MNIST grayscale images\n",
    "\n",
    "# Attack params\n",
    "input_model = 'trained_model_MNIST.pth'\n",
    "target = 2\n",
    "learning_rate = 0.01\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "batch_size = private_dataset_size\n",
    "epochs = 1\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2dfc933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make reproducible\n",
    "random.seed(rng_seed)\n",
    "torch.manual_seed(rng_seed)\n",
    "np.random.seed(rng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "158c6da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model if specified\n",
    "if input_model != None:\n",
    "    trained_model_state_dict = torch.load(input_model)\n",
    "else:\n",
    "    trained_model_state_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "426a1b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 10 client dataloaders\n",
      "Private dataset 0: [4, 3, 9]. Missing digits: [0, 1, 2, 5, 6, 7, 8]\n",
      "Private dataset 1: [7, 8, 3]. Missing digits: [0, 1, 2, 4, 5, 6, 9]\n",
      "Private dataset 2: [8, 9, 4]. Missing digits: [0, 1, 2, 3, 5, 6, 7]\n",
      "Private dataset 3: [5, 7, 1]. Missing digits: [0, 2, 3, 4, 6, 8, 9]\n",
      "Private dataset 4: [0, 8, 6]. Missing digits: [1, 2, 3, 4, 5, 7, 9]\n",
      "Private dataset 5: [0, 6, 9]. Missing digits: [1, 2, 3, 4, 5, 7, 8]\n",
      "Private dataset 6: [6, 9, 2]. Missing digits: [0, 1, 3, 4, 5, 7, 8]\n",
      "Private dataset 7: [5, 0, 8]. Missing digits: [1, 2, 3, 4, 6, 7, 9]\n",
      "Private dataset 8: [1, 8, 8]. Missing digits: [0, 2, 3, 4, 5, 6, 7, 9]\n",
      "Private dataset 9: [2, 2, 8]. Missing digits: [0, 1, 3, 4, 5, 6, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "# Download and transform MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # normalization params for MNIST\n",
    "])\n",
    "\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "clients_dataloaders = []\n",
    "for i in range(num_clients):\n",
    "    client_indices = random.sample(range(len(mnist_train)), private_dataset_size)\n",
    "    client_subset = Subset(mnist_train, client_indices)\n",
    "    dataloader = DataLoader(client_subset, batch_size=batch_size, shuffle=True)\n",
    "    clients_dataloaders.append(dataloader)\n",
    "\n",
    "print(f\"Prepared {num_clients} client dataloaders\")\n",
    "\n",
    "# inspect private datasets\n",
    "for idx in range(len(clients_dataloaders)):\n",
    "    data = []\n",
    "    \n",
    "    for dp, y in clients_dataloaders[idx]:\n",
    "        data.extend(y.tolist())\n",
    "    print('Private dataset ', idx, ': ', data, '. Missing digits: ', [x for x in range(10) if x not in data], sep='')\n",
    "\n",
    "test_loader = DataLoader(dataset=mnist_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad44dee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target is client 2\n",
      "\n",
      "Gradient comparison (L2 norm of difference):\n",
      "conv1.weight: L2 diff = 8.110032e-06\n",
      "conv1.bias: L2 diff = 3.144434e-06\n",
      "conv2.weight: L2 diff = 1.077320e-05\n",
      "conv2.bias: L2 diff = 5.964426e-07\n",
      "conv3.weight: L2 diff = 1.661216e-05\n",
      "conv3.bias: L2 diff = 6.396044e-07\n",
      "fc.weight: L2 diff = 3.950195e-06\n",
      "fc.bias: L2 diff = 1.068994e-07\n",
      "Comparing target update with global update:\n",
      "Average MSE: 0.0082\n",
      "Average cosine similarity: 0.9999\n",
      "Gradient Suppression Attack complete!\n"
     ]
    }
   ],
   "source": [
    "# Attack round\n",
    "if target == 'all':\n",
    "    for i in range(num_clients):\n",
    "        global_model, local_updates = gradient_suppression(\n",
    "            clients_dataloaders=clients_dataloaders,\n",
    "            input_shape=input_shape,\n",
    "            num_classes=num_classes,\n",
    "            trained_model_state_dict = trained_model_state_dict,\n",
    "            target=i,\n",
    "            criterion=loss_fn,\n",
    "            lr=learning_rate,\n",
    "            epochs=epochs,\n",
    "            device=device,\n",
    "            model=model\n",
    "        )\n",
    "        filename = 'target_' + str(i) + '.pth'\n",
    "        torch.save(global_model.state_dict(), filename)\n",
    "else:\n",
    "    global_model, local_updates = gradient_suppression(\n",
    "        clients_dataloaders=clients_dataloaders,\n",
    "        input_shape=input_shape,\n",
    "        num_classes=num_classes,\n",
    "        trained_model_state_dict = trained_model_state_dict,\n",
    "        target=target,\n",
    "        criterion=loss_fn,\n",
    "        lr=learning_rate,\n",
    "        epochs=epochs,\n",
    "        device=device,\n",
    "        model=model\n",
    "    )\n",
    "\n",
    "print(\"Gradient Suppression Attack complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8ac19db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save global update to file\n",
    "filename = 'GS_target_' + str(target) + '.pth'\n",
    "torch.save(global_model.state_dict(), filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
