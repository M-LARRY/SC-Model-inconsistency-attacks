{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9e01fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from federated_learning import *\n",
    "from gradient_suppression import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a1478f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "model = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "rng_seed = 0\n",
    "\n",
    "# Clients\n",
    "num_clients = 10\n",
    "private_dataset_size = 1\n",
    "\n",
    "# Dataset\n",
    "num_classes = 10\n",
    "input_shape = (1, 28, 28)  # MNIST grayscale images\n",
    "\n",
    "# Attack params\n",
    "input_model = 'trained_model_MNIST.pth'\n",
    "target = 'all'\n",
    "learning_rate = 0.01\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "batch_size = 1\n",
    "epochs = 1\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e2dfc933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make reproducible\n",
    "random.seed(rng_seed)\n",
    "torch.manual_seed(rng_seed)\n",
    "np.random.seed(rng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "158c6da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model if specified\n",
    "if input_model != None:\n",
    "    trained_model_state_dict = torch.load(input_model)\n",
    "else:\n",
    "    trained_model_state_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "426a1b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 10 client dataloaders\n",
      "Private dataset 0: [4]. Missing digits: [0, 1, 2, 3, 5, 6, 7, 8, 9]\n",
      "Private dataset 1: [9]. Missing digits: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "Private dataset 2: [3]. Missing digits: [0, 1, 2, 4, 5, 6, 7, 8, 9]\n",
      "Private dataset 3: [3]. Missing digits: [0, 1, 2, 4, 5, 6, 7, 8, 9]\n",
      "Private dataset 4: [8]. Missing digits: [0, 1, 2, 3, 4, 5, 6, 7, 9]\n",
      "Private dataset 5: [7]. Missing digits: [0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "Private dataset 6: [9]. Missing digits: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "Private dataset 7: [4]. Missing digits: [0, 1, 2, 3, 5, 6, 7, 8, 9]\n",
      "Private dataset 8: [8]. Missing digits: [0, 1, 2, 3, 4, 5, 6, 7, 9]\n",
      "Private dataset 9: [1]. Missing digits: [0, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# Download and transform MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # normalization params for MNIST\n",
    "])\n",
    "\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "clients_dataloaders = []\n",
    "for i in range(num_clients):\n",
    "    client_indices = random.sample(range(len(mnist_train)), private_dataset_size)\n",
    "    client_subset = Subset(mnist_train, client_indices)\n",
    "    dataloader = DataLoader(client_subset, batch_size=batch_size, shuffle=True)\n",
    "    clients_dataloaders.append(dataloader)\n",
    "\n",
    "print(f\"Prepared {num_clients} client dataloaders\")\n",
    "\n",
    "# inspect private datasets\n",
    "for idx in range(len(clients_dataloaders)):\n",
    "    data = []\n",
    "    \n",
    "    for dp, y in clients_dataloaders[idx]:\n",
    "        data.append(int(y[0]))\n",
    "    print('Private dataset ', idx, ': ', data, '. Missing digits: ', [x for x in range(10) if x not in data], sep='')\n",
    "\n",
    "test_loader = DataLoader(dataset=mnist_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ad44dee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target is client 0\n",
      "Comparing target update with global update:\n",
      "Average MSE: 0.0081\n",
      "Average cosine similarity: 0.9999\n",
      "Gradient Suppression Attack complete!\n"
     ]
    }
   ],
   "source": [
    "# Attack round\n",
    "global_model, local_updates = gradient_suppression(\n",
    "    clients_dataloaders=clients_dataloaders,\n",
    "    input_shape=input_shape,\n",
    "    num_classes=num_classes,\n",
    "    trained_model_state_dict = trained_model_state_dict,\n",
    "    target=target,\n",
    "    criterion=loss_fn,\n",
    "    lr=learning_rate,\n",
    "    epochs=epochs,\n",
    "    device=device,\n",
    "    model=model\n",
    ")\n",
    "\n",
    "print(\"Gradient Suppression Attack complete!\")\n",
    "\n",
    "if target == 'all':\n",
    "    for i in range(num_clients):\n",
    "        global_model, local_updates = gradient_suppression(\n",
    "            clients_dataloaders=clients_dataloaders,\n",
    "            input_shape=input_shape,\n",
    "            num_classes=num_classes,\n",
    "            trained_model_state_dict = trained_model_state_dict,\n",
    "            target=i,\n",
    "            criterion=loss_fn,\n",
    "            lr=learning_rate,\n",
    "            epochs=epochs,\n",
    "            device=device,\n",
    "            model=model\n",
    "        )\n",
    "        filename = 'target_' + str(i) + '.pth'\n",
    "        torch.save(global_model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "12c00822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug\n",
    "# for i in range(num_clients):\n",
    "#     row = []\n",
    "#     for j in range(num_clients):\n",
    "#         avg_cos_sim = state_dicts_cosine_similarity(local_updates[i], local_updates[j])\n",
    "#         # avg_cos_sim = i == j\n",
    "#         row.append(avg_cos_sim)\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c8ac19db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save global update to file\n",
    "filename = 'target_' + str(target) + '.pth'\n",
    "torch.save(global_model.state_dict(), filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
