{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf6d5d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset, random_split\n",
    "from inference_attack import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf8657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "model = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "rng_seed = 0\n",
    "dataset_name = \"MNIST\"                         # \"MNIST\" or \"CIFAR10\"\n",
    "data_path = \"./data\"\n",
    "\n",
    "# Part 1 Use pretrained model to create a dataset for gradient classification\n",
    "pretrained_model_path = \"trained_model_MNIST.pth\"\n",
    "criterion_pretrained_model = torch.nn.CrossEntropyLoss()\n",
    "num_classes = 10\n",
    "inference_dataset_size = 500\n",
    "batch_size_pretrained_model = 2\n",
    "\n",
    "# Part 2 Train gradient classifier on gradient dataset\n",
    "learning_rate_gradient_classifier = 0.001\n",
    "criterion_grad_classifier = kl_div\n",
    "train_size = 0.7\n",
    "test_size = 1 - train_size\n",
    "num_epochs = 10\n",
    "batch_size_gradient_classifier = 16\n",
    "\n",
    "# Part 3 Make inference on estimated gradient update\n",
    "target_model_path = \"GS_target_1.pth\"\n",
    "learning_rate_pretrained_model = 0.01\n",
    "num_clients_fl = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fed30bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make reproducible\n",
    "random.seed(rng_seed)\n",
    "torch.manual_seed(rng_seed)\n",
    "np.random.seed(rng_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e910d2fc",
   "metadata": {},
   "source": [
    "## Part 1. Use pretrained model to create a dataset for gradient classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a09708db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset (we use test datasets to train the model on samples that have not been used in training of the global model)\n",
    "if dataset_name == \"MNIST\":\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    dataset = datasets.MNIST(root=data_path, train=False, download=True, transform=transform)\n",
    "    input_shape = (1, 28, 28)\n",
    "\n",
    "elif dataset_name == \"CIFAR10\":\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ])\n",
    "    dataset = datasets.CIFAR10(root=data_path, train=False, download=True, transform=transform)\n",
    "    input_shape = (3, 32, 32)\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n",
    "\n",
    "indices = random.sample(range(len(dataset)), inference_dataset_size)\n",
    "dataset = Subset(dataset, indices=indices)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size_pretrained_model, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88bc0655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pretrained model\n",
    "theta_0 = torch.load(pretrained_model_path)\n",
    "\n",
    "if model == 1:\n",
    "    inference_model = Model1(input_shape, num_classes).to(device)\n",
    "elif model == 2:\n",
    "    inference_model = Model2(input_shape, num_classes).to(device)\n",
    "else:\n",
    "    print('Unknown model:', model)\n",
    "\n",
    "inference_model.load_state_dict(state_dict=theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b27d9069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect gradient features\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "inference_model.to(device)\n",
    "inference_model.train() # eval can make some layers behave differently (Not in our case)\n",
    "\n",
    "for x, y in dataloader:\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    output = inference_model(x)\n",
    "    loss = criterion_pretrained_model(output, y)\n",
    "\n",
    "    # Compute gradients w.r.t. model parameters (except fc)\n",
    "    fc_params = set(p for p in inference_model.fc.parameters())\n",
    "    all_params = list(inference_model.parameters())\n",
    "    params_except_fc = [p for p in all_params if p not in fc_params]\n",
    "    grad = torch.autograd.grad(loss, params_except_fc, retain_graph=False)\n",
    "    # grad = torch.autograd.grad(loss, inference_model.parameters(), retain_graph=False)\n",
    "    grad_vector = torch.cat([g.view(-1) for g in grad])  # Flatten and concatenate\n",
    "\n",
    "    # Detach and store\n",
    "    features.append(grad_vector.detach().cpu().float())\n",
    "    labels.append(multi_hot_encode(y, num_classes))\n",
    "\n",
    "features = torch.stack(features)\n",
    "labels = torch.stack(labels).float()\n",
    "\n",
    "dataset = TensorDataset(features, labels)\n",
    "input_dim = features.shape[1]\n",
    "output_dim = labels.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16963933",
   "metadata": {},
   "source": [
    "## Part 2. Train gradient classifier on gradient dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3cba6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175 75\n"
     ]
    }
   ],
   "source": [
    "# dataset split\n",
    "tmp_train = int(train_size*inference_dataset_size/batch_size_pretrained_model)\n",
    "tmp_test = int(inference_dataset_size/batch_size_pretrained_model-tmp_train)\n",
    "print(tmp_train, tmp_test)\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [tmp_train, tmp_test])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size_gradient_classifier, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size_gradient_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9834dc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 4.4018 | Accuracy: 0.00%\n",
      "Test Loss: 4.4331 | Cosine Similarity: 0.4804\n",
      "Epoch 2/10 | Loss: 4.3495 | Accuracy: 0.00%\n",
      "Test Loss: 4.3466 | Cosine Similarity: 0.6351\n",
      "Epoch 3/10 | Loss: 4.1464 | Accuracy: 0.00%\n",
      "Test Loss: 4.0997 | Cosine Similarity: 0.7510\n",
      "Epoch 4/10 | Loss: 3.8823 | Accuracy: 0.00%\n",
      "Test Loss: 3.8696 | Cosine Similarity: 0.7621\n",
      "Epoch 5/10 | Loss: 3.7541 | Accuracy: 0.00%\n",
      "Test Loss: 3.7849 | Cosine Similarity: 0.7941\n",
      "Epoch 6/10 | Loss: 3.7233 | Accuracy: 0.00%\n",
      "Test Loss: 3.7624 | Cosine Similarity: 0.7966\n",
      "Epoch 7/10 | Loss: 3.7060 | Accuracy: 0.00%\n",
      "Test Loss: 3.7572 | Cosine Similarity: 0.7941\n",
      "Epoch 8/10 | Loss: 3.6940 | Accuracy: 0.00%\n",
      "Test Loss: 3.7550 | Cosine Similarity: 0.8064\n",
      "Epoch 9/10 | Loss: 3.6868 | Accuracy: 0.00%\n",
      "Test Loss: 3.7509 | Cosine Similarity: 0.8136\n",
      "Epoch 10/10 | Loss: 3.6812 | Accuracy: 0.00%\n",
      "Test Loss: 3.7427 | Cosine Similarity: 0.8299\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "grad_classifier_model = GradientClassifier(input_dim=input_dim, output_dim=output_dim)\n",
    "grad_classifier_model.to(device)\n",
    "\n",
    "train_grad_classifier(grad_classifier_model, train_loader, test_loader, criterion_grad_classifier, num_epochs=num_epochs, lr=learning_rate_gradient_classifier, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a04aafa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.7427 | Cosine Similarity: 0.8299\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "test_preds = evaluate_model(grad_classifier_model, test_loader, criterion_grad_classifier, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3449ad44",
   "metadata": {},
   "source": [
    "## Part 3. Make inference on estimated gradient update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce90cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load true gradient update\n",
    "true_grad = torch.load('DEBUG_true_grads.pth')\n",
    "# remove fc layer\n",
    "true_grad = remove_layers(true_grad, ['fc.weight', 'fc.bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25f49879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity between estimated gradient and true gradient: -0.1768\n",
      "mse between estimated gradient and true gradient: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Estimate gradient update\n",
    "theta_0 = torch.load(pretrained_model_path)\n",
    "theta_1 = torch.load(target_model_path)\n",
    "# remove fc layer\n",
    "theta_0 = remove_layers(theta_0, ['fc.weight', 'fc.bias'])\n",
    "theta_1 = remove_layers(theta_1, ['fc.weight', 'fc.bias'])\n",
    "# \n",
    "theta_1 = state_dict_scale(theta_1, num_clients_fl)\n",
    "est_grad = estimate_gradient(theta_0, theta_1, learning_rate_pretrained_model)\n",
    "\n",
    "cs = state_dicts_average_cosine_similarity(est_grad, true_grad)\n",
    "mse = state_dicts_mse(est_grad, true_grad)\n",
    "print(f'cosine similarity between estimated gradient and true gradient: {cs:.4f}')\n",
    "print(f'mse between estimated gradient and true gradient: {mse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ecdfbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00020806053362321109, 0.0011453658808022738, 0.00021091519738547504, 0.00011163038288941607, 0.0034748497419059277, 0.0007314719841815531, 0.0005469466559588909, 0.00016796666022855788, 0.00030751232407055795, 0.9930952191352844]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference\n",
    "est_grad_vector = torch.cat([est_grad[key].view(-1) for key in est_grad.keys()]).unsqueeze(0)\n",
    "inferred = grad_classifier_model(est_grad_vector)\n",
    "inferred = inferred.tolist()[0]\n",
    "print(inferred)\n",
    "plt.bar(range(num_classes), inferred)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
