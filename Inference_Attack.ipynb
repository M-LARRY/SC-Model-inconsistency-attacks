{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf6d5d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset, random_split\n",
    "from inference_attack import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf8657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "model = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "rng_seed = 0\n",
    "dataset_name = \"MNIST\"                         # \"MNIST\" or \"CIFAR10\"\n",
    "data_path = \"./data\"\n",
    "\n",
    "# Part 1 Use pretrained model to create a dataset for gradient classification\n",
    "pretrained_model_path = \"trained_model_MNIST.pth\"\n",
    "criterion_pretrained_model = torch.nn.CrossEntropyLoss()\n",
    "num_classes = 10\n",
    "inference_dataset_size = 500\n",
    "batch_size_pretrained_model = 1\n",
    "\n",
    "# Part 2 Train gradient classifier on gradient dataset\n",
    "learning_rate_gradient_classifier = 0.001\n",
    "criterion_grad_classifier = kl_div\n",
    "# criterion_grad_classifier = nn.BCELoss()\n",
    "train_size = 0.7\n",
    "test_size = 1 - train_size\n",
    "num_epochs = 3\n",
    "batch_size_gradient_classifier = 16\n",
    "\n",
    "# Part 3 Make inference on estimated gradient update\n",
    "target_model_path = \"GS_target_0.pth\"\n",
    "learning_rate_pretrained_model = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fed30bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make reproducible\n",
    "random.seed(rng_seed)\n",
    "torch.manual_seed(rng_seed)\n",
    "np.random.seed(rng_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e910d2fc",
   "metadata": {},
   "source": [
    "## Part 1. Use pretrained model to create a dataset for gradient classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a09708db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset (we use test datasets to train the model on samples that have not been used in training of the global model)\n",
    "if dataset_name == \"MNIST\":\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    dataset = datasets.MNIST(root=data_path, train=False, download=True, transform=transform)\n",
    "    input_shape = (1, 28, 28)\n",
    "\n",
    "elif dataset_name == \"CIFAR10\":\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ])\n",
    "    dataset = datasets.CIFAR10(root=data_path, train=False, download=True, transform=transform)\n",
    "    input_shape = (3, 32, 32)\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n",
    "\n",
    "indices = random.sample(range(len(dataset)), inference_dataset_size)\n",
    "dataset = Subset(dataset, indices=indices)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size_pretrained_model, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88bc0655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pretrained model\n",
    "theta_0 = torch.load(pretrained_model_path)\n",
    "\n",
    "if model == 1:\n",
    "    inference_model = Model1(input_shape, num_classes).to(device)\n",
    "elif model == 2:\n",
    "    inference_model = Model2(input_shape, num_classes).to(device)\n",
    "else:\n",
    "    print('Unknown model:', model)\n",
    "\n",
    "inference_model.load_state_dict(state_dict=theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b27d9069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect gradient features\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "inference_model.to(device)\n",
    "inference_model.train() # eval can make some layers behave differently (Not in our case)\n",
    "\n",
    "for x, y in dataloader:\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    output = inference_model(x)\n",
    "    loss = criterion_pretrained_model(output, y)\n",
    "\n",
    "    # print(\"pr:\", output, \"gt:\", y)\n",
    "\n",
    "    # Compute gradients w.r.t. model parameters\n",
    "    grad = torch.autograd.grad(loss, inference_model.parameters(), retain_graph=False)\n",
    "    # grad = torch.autograd.grad(loss, [inference_model.fc1.weight, inference_model.fc1.bias], retain_graph=False)\n",
    "    grad_vector = torch.cat([g.view(-1) for g in grad])  # Flatten and concatenate\n",
    "\n",
    "    # Detach and store\n",
    "    features.append(grad_vector.detach().cpu().float())\n",
    "    # labels.append(one_hot_encode(y.item(), num_classes))\n",
    "    labels.append(multi_hot_encode(y, num_classes))\n",
    "    # print(multi_hot_encode(y, num_classes))\n",
    "    \n",
    "    # DEBUG\n",
    "    if torch.equal(multi_hot_encode(y, num_classes), multi_hot_encode(torch.tensor([7]), num_classes)):\n",
    "        saved_grad = grad_vector.unsqueeze(0)\n",
    "\n",
    "features = torch.stack(features)\n",
    "labels = torch.stack(labels).float()\n",
    "#labels = torch.stack([y.detach().clone().float32() for y in labels])\n",
    "\n",
    "dataset = TensorDataset(features, labels)\n",
    "input_dim = features.shape[1]\n",
    "output_dim = labels.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16963933",
   "metadata": {},
   "source": [
    "## Part 2. Train gradient classifier on gradient dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3cba6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 150\n"
     ]
    }
   ],
   "source": [
    "# dataset split\n",
    "tmp_train = int(train_size*inference_dataset_size/batch_size_pretrained_model)\n",
    "tmp_test = int(inference_dataset_size/batch_size_pretrained_model-tmp_train)\n",
    "print(tmp_train, tmp_test)\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [tmp_train, tmp_test])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size_gradient_classifier, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size_gradient_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9834dc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | Loss: 2.0684 | Accuracy: 0.00%\n",
      "Test Loss: 1.8787 | Cosine Similarity: 0.7277\n",
      "Epoch 2/3 | Loss: 1.8140 | Accuracy: 0.00%\n",
      "Test Loss: 1.7673 | Cosine Similarity: 0.8111\n",
      "Epoch 3/3 | Loss: 1.7178 | Accuracy: 0.00%\n",
      "Test Loss: 1.7145 | Cosine Similarity: 0.8391\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "grad_classifier_model = GradientClassifier(input_dim=input_dim, output_dim=output_dim)\n",
    "grad_classifier_model.to(device)\n",
    "\n",
    "train_grad_classifier(grad_classifier_model, train_loader, test_loader, criterion_grad_classifier, num_epochs=num_epochs, lr=learning_rate_gradient_classifier, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a04aafa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.7145 | Cosine Similarity: 0.8391\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "test_preds = evaluate_model(grad_classifier_model, test_loader, criterion_grad_classifier, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3449ad44",
   "metadata": {},
   "source": [
    "## Part 3. Make inference on estimated gradient update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72fe697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the target gradient update as theta_0 - theta_1 / lr\n",
    "# theta_1 = torch.load(target_model_path)\n",
    "# est_grad = elementwise_diff_state_dicts(theta_0, theta_1, learning_rate_pretrained_model)\n",
    "# est_grad_vector = dict_to_tensor(est_grad).unsqueeze(0)\n",
    "# for key in est_grad.keys():\n",
    "#     print(est_grad[key].shape)\n",
    "\n",
    "# est_grad_vector = torch.cat([est_grad[key].view(-1) for key in est_grad.keys()]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a112747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est_grad and true_grad -0.020676113228546456\n",
      "theta_0 and theta_0_D 0.9620247259736061\n",
      "theta_1 and theta_1_D 0.9618029594421387\n",
      "est_grad and est_grad_D -0.02068660664372146\n",
      "true_grad and est_grad_D 1.0000000447034836\n",
      "----------\n",
      "-0.07688275910913944\n"
     ]
    }
   ],
   "source": [
    "# estimate update gradient and compare with true update\n",
    "theta_0 = torch.load('trained_model_MNIST.pth')\n",
    "theta_1 = torch.load('target_0.pth')\n",
    "est_grad = elementwise_diff_state_dicts(theta_0, theta_1, learning_rate_pretrained_model)\n",
    "\n",
    "theta_0_D = torch.load('DEBUG_initial_state.pth')\n",
    "theta_1_D = torch.load('DEBUG_updated_state.pth')\n",
    "est_grad_D = elementwise_diff_state_dicts(theta_0_D, theta_1_D, learning_rate_pretrained_model)\n",
    "\n",
    "true_grad = torch.load('DEBUG_true_grads.pth')\n",
    "\n",
    "print('est_grad and true_grad', state_dicts_average_cosine_similarity(est_grad, true_grad))\n",
    "print('theta_0 and theta_0_D', state_dicts_average_cosine_similarity(theta_0, theta_0_D))\n",
    "print('theta_1 and theta_1_D', state_dicts_average_cosine_similarity(theta_1, theta_1_D))\n",
    "print('est_grad and est_grad_D', state_dicts_average_cosine_similarity(est_grad, est_grad_D))\n",
    "print('true_grad and est_grad_D', state_dicts_average_cosine_similarity(true_grad, est_grad_D))\n",
    "print('----------')\n",
    "est_grad_alt = elementwise_diff_state_dicts(theta_0, theta_1_D, learning_rate_pretrained_model)\n",
    "print(state_dicts_average_cosine_similarity(est_grad_alt, true_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ede59329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference\n",
    "est_grad_vector = torch.cat([est_grad[key].view(-1) for key in est_grad.keys()]).unsqueeze(0)\n",
    "inferred = grad_classifier_model(est_grad_vector)\n",
    "inferred = inferred.tolist()[0]\n",
    "print(inferred)\n",
    "plt.bar(range(num_classes), inferred)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
